Computer Graphics Practical
===========================

Introduction
============
The aim of the project was to create a voxel-based video game. The game itself was not finished, however the graphical components were. 

Demonstration Files and Controls
================================

The following executable files are supplied for demonstration:
    impact_demo.exe     - shows a landscape and the 'shockwave' effect.

Additionally, the directory 'presentation' contains a presentation file with video and image demonstration.

The camera in the demonstration executables is controlled as follows: 
Space, Shift:   Move forwards, backwards
WASD:           Turn up, left, down, right
Arrow Keys:     Move up, left, down, right

Execution and Compilation
=========================

To execute any of the binaries, the graphics driver needs to support opengl 4.5. 

To compile, glew32 and sdl2 need to be installed and it should be ensured that those can be found by cmake. I compiled the project using mingw gcc, cmake and ninja. 


Graphics
========

Triangle models are created from magicavoxel model files, which is a simple format for voxel models. These consist of a color palette in the form of an size 255 rgba array and for each voxel (a colored cube in space of constant size) the xyz coordinate of its center and the index of its color in the color palette. From these files I create triangle models with vertices containing position, normal and color information. Only outside faces are generated, i.e. faces between two voxels are not generated. However the resulting meshes are not optimized further.

To arrange models within the scene, voxelmaps have again been used, however in this instance each voxel represents not just a color but a model. This allows the storage of terrain with relatively little effort.

Lighting is implemented through forward shading for ambient, directional and point light sources using lambertian reflection and Phong shading. 

A simple displacement effect is implemented, which can move vertices in space to create for example a wave shaped effect. In theory any displacement function mapping points in space to points in space can be used, however currently only wave shaped functions can be passed to the shader. As an experiment, two different ways of computing vertex normals are implemented for this: the first computes for each triangle the corresponding normal from its vertices and sets this normal for its vertices. This is implemented in the geometry shader and it leads to visible triangle edges. The second way computes the normal through approximated derivatives of the displacement function. This can be implemented in the vertex shader and leads to a smoother appearance.

Further Thoughts
================
An issue that came up relatively quickly is performance. In the pacman map scene, increasing the boundary of the map to 10 leads to a noticable loss in framerate. This is mostly because faces between adjacent walls are drawn. The map is 50 * 50 * 2 and each model is generated by a 6 * 6 * 6 voxelmap. To give an approximation of the number of faces that need to be drawn, assume that each 'tile' is a full cube, so it has 6 * 6 * 6 * 2 surface triangles. Thus the total number of faces to be drawn is roughly 50^2 * 2 * 6^3 * 2 = 2160000 triangles. This number could be reduced for example by optimizing the voxel meshes or by only drawing the outer triangles of the models if necessary.

SDL was used for window creation and input. GLM was used for calculations. The entity component system 'entt' was used to represent the state all entities in the scene and animate them. Magicavoxel was used for the graphical assets in the scenes.
